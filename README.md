# GFlowNet for Genetic Circuits Design

A clean, modular implementation of GFlowNet for genetic circuits design with improved architecture and configuration management.

## ğŸ¯ **Simple Training Interface**

**One script, clean interface**: `python train.py --env gridenv2 --reward somitogenesis`

No more massive argument lists or confusing multiple training scripts!

## ğŸ—ï¸ **Project Structure**

```
discrete-gflownet/
â”œâ”€â”€ train.py                    # ğŸš€ Main training script (your entry point!)
â”œâ”€â”€ trainer.py                  # ğŸ¯ Core training logic & CheckpointManager
â”œâ”€â”€ disc_gflownet/              # ğŸ“¦ Main package
â”‚   â”œâ”€â”€ agents/                 # ğŸ¤– Agent implementations (TB, DB, FlowNet)
â”‚   â”œâ”€â”€ envs/                   # ğŸŒ Environment implementations
â”‚   â”œâ”€â”€ nets/                   # ğŸ§  Neural network architectures
â”‚   â””â”€â”€ utils/                  # ğŸ› ï¸ Utilities (logging, plotting, caching)
â”œâ”€â”€ configs/                    # âš™ï¸ Configuration management
â”‚   â”œâ”€â”€ __init__.py             # ğŸ“‹ Environment registry
â”‚   â”œâ”€â”€ baseenv_config.py       # ğŸ”§ Base configuration class
â”‚   â”œâ”€â”€ gridenv_config.py       # ğŸ  GridEnv configuration
â”‚   â”œâ”€â”€ gridenv2_config.py      # ğŸ  GridEnv2 configuration
â”‚   â””â”€â”€ reward_configs.py       # ğŸ Reward function registry
â”œâ”€â”€ reward_func/                # ğŸ¯ Reward function implementations
â”œâ”€â”€ analysis/                   # ğŸ“Š Analysis tools and scripts
â”œâ”€â”€ scripts/                    # ğŸ”§ Utility scripts
â”‚   â””â”€â”€ test_configs.py         # ğŸ§ª Configuration testing
â”œâ”€â”€ notebooks/                  # ğŸ““ Organized notebooks
â”‚   â”œâ”€â”€ experiments/            # ğŸ§ª Experimental notebooks
â”‚   â”œâ”€â”€ analysis/              # ğŸ“Š Analysis notebooks
â”‚   â””â”€â”€ testing/               # ğŸ” Testing notebooks
â”œâ”€â”€ runs/                      # ğŸ’¾ Training outputs
â””â”€â”€ docs/                      # ğŸ“š Documentation

```

## ğŸš€ **Quick Start**

**Main Training Script**: `train.py` - Your single entry point for all training!

### Basic Usage
```bash
# Train with default GridEnv and somitogenesis reward
python train.py

# Use specific environment and reward  
python train.py --env gridenv2 --reward somitogenesis

# Override specific settings
python train.py --env gridenv --steps 2000 --workers 16 --device cuda
```

### Available Options
```bash
# Environments
--env {gridenv, gridenv2, base}

# Reward functions  
--reward {coord, oscillator, somitogenesis}

# Common overrides
--device {cpu, cuda}     # Override device
--steps N                # Override training steps
--workers N              # Override worker count
```

## âš™ï¸ **Configuration System**

### How It Works
1. **Environment configs** in `configs/` define all parameters
2. **Reward functions** in `reward_func/` provide fitness landscapes  
3. **No massive CLI** - just select environment + reward
4. **Easy customization** - edit config files directly

### Example: Customizing Parameters
```python
# Edit configs/gridenv_config.py
class GridEnvConfig(BaseEnvConfig):
    n_train_steps = 5000    # More training steps
    n_workers = 16          # More parallel workers
    method = 'tb'           # Use Trajectory Balance
    device = 'cuda'         # Use GPU
```

## ğŸ—ï¸ **Architecture Improvements**

### Before vs After

| **Before (Old train.py)** | **After (Refactored)** |
|---------------------------|------------------------|
| âŒ 248 lines with massive arg parser | âœ… Clean 80-line main script |
| âŒ Global variables (`global losses, zs`) | âœ… Encapsulated in `GFlowNetTrainer` class |  
| âŒ Monolithic `main()` function | âœ… Modular trainer with clear responsibilities |
| âŒ Hardcoded env selection | âœ… Dynamic environment registry |
| âŒ Commented-out config blocks | âœ… Clean config class hierarchy |
| âŒ Mixed training/logging logic | âœ… Separate `CheckpointManager` class |

### Key Classes

#### `GFlowNetTrainer`
- **Encapsulates** all training state (no globals!)
- **Modular setup** methods for env/agent/logging
- **Clean training loop** with step-by-step logic
- **Robust error handling** with checkpoint recovery

#### `CheckpointManager`  
- **Dedicated checkpoint** saving/loading
- **Interruption handling** for graceful shutdowns
- **Consistent state** preservation across runs

## ğŸ§ª **Development Workflow**

### Adding New Environments
1. Create config in `configs/my_env_config.py`
2. Add to `ENVS` registry in `configs/__init__.py`
3. Implement environment in `disc_gflownet/envs/`

### Adding New Reward Functions
1. Implement in `reward_func/my_reward.py`
2. Add to `REWARD_FUNCTIONS` in `configs/reward_configs.py`

### Running Experiments
```bash
# Quick experiments
python train.py --env gridenv --steps 500

# Production runs  
python train.py --env gridenv2 --steps 10000 --workers 32
```

## ğŸ“Š **Notebooks Organization**

- **`notebooks/experiments/`** - New experiment notebooks
- **`notebooks/analysis/`** - Data analysis and visualization  
- **`notebooks/testing/`** - Testing and validation notebooks

**Note**: All existing notebooks have been updated with proper import paths. For new notebooks, see `notebooks/NOTEBOOK_SETUP.md` for the required setup code.

## ğŸ”§ **CLI Memory**

The system remembers your preferences. Based on your usage patterns, it will use `--env` instead of `--config` for environment specification.

## ğŸ¯ **Benefits of This Refactor**

1. **ğŸ§¹ Clean separation** - No more commented-out code blocks
2. **ğŸ”„ Easy experimentation** - Switch environments with single flag
3. **ğŸ“‹ Reproducibility** - Each config is self-contained
4. **ğŸ”§ Extensibility** - Add new environments without touching core code
5. **âš¡ Performance** - Better organized multiprocessing
6. **ğŸ›¡ï¸ Robustness** - Proper error handling and state management
7. **ğŸ“š Maintainability** - Clear class structure and responsibilities

## ğŸ”® **Usage Examples**

```bash
# Quick GridEnv experiment
python train.py --env gridenv --steps 1000

# Your preferred interface (works perfectly!)
python train.py --env gridenv2 --reward somitogenesis

# Long GridEnv2 training with multiprocessing  
python train.py --env gridenv2 --steps 10000 --workers 20

# GPU accelerated training
python train.py --env gridenv --device cuda --steps 5000

# Different reward landscapes
python train.py --reward coord --steps 2000
python train.py --reward oscillator --steps 2000  
```

Your research just got a lot more organized! ğŸš€ 